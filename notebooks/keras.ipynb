{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import TimeDistributedDense, Activation, Dropout\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConLLReader(object):\n",
    "    def __init__(self, fname, lowercase=False, max_length=80):\n",
    "        self.fname = fname\n",
    "        self.lowercase = lowercase\n",
    "        self.max_length = max_length\n",
    "    def __iter__(self):\n",
    "        for line in open(self.fname):\n",
    "            tokens = line.strip().split(' ')\n",
    "            if self.lowercase:\n",
    "                tokens = [t.lower() for t in tokens]\n",
    "            tokens = list(pad(tokens, size=self.max_length, padding='EOS'))\n",
    "            yield tokens\n",
    "            \n",
    "from itertools import chain, repeat, islice\n",
    "\n",
    "def pad_infinite(iterable, padding=None):\n",
    "    return chain(iterable, repeat(padding))\n",
    "\n",
    "def pad(iterable, size, padding=None):\n",
    "    return islice(pad_infinite(iterable, padding), size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_to_tokens(c, d):\n",
    "    seqs = list(c)\n",
    "    seqs_tokens = []\n",
    "    for seq in seqs:\n",
    "        tokens = []\n",
    "        for t in seq:\n",
    "            if t in d.token2id:\n",
    "                tokens.append(d.token2id[t])\n",
    "            else:\n",
    "                tokens.append(len(d))\n",
    "        seqs_tokens.append(tokens)\n",
    "    return seqs_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getXandY(corpus_tokens, tags_tokens):\n",
    "    X = np.array(corpus_tokens)\n",
    "    y_ = np.array(tags_tokens)\n",
    "    seq_len = X.shape[1]\n",
    "    num_tags = len(tags_dictionary)\n",
    "    om = OneHotEncoder(n_values=num_tags)\n",
    "    y = om.fit_transform(y_).toarray()\n",
    "    y = y.reshape(-1, seq_len, num_tags)\n",
    "    print \"X:shape\",X.shape\n",
    "    print \"Y:shape\",y.shape\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dump_conll_eval(text_file, tags_file, output_file, preds):\n",
    "    cf = open(text_file)\n",
    "    tf = open(tags_file)\n",
    "    of = open(output_file, 'w')\n",
    "    sents = [line.strip() for line in cf]\n",
    "    tags = [line.strip() for line in tf]\n",
    "    \n",
    "    sents_tokens = []\n",
    "    tags_tokens = []\n",
    "    for sent, tag in zip(sents, tags):\n",
    "        stokens = sent.split(' ')\n",
    "        stags = tag.split(' ')\n",
    "        sents_tokens.append(stokens)\n",
    "        tags_tokens.append(stags)\n",
    "        \n",
    "    for i in np.arange(0, len(sents_tokens)):\n",
    "        tuples = zip(sents_tokens[i], tags_tokens[i], preds[i])\n",
    "        for t in tuples:\n",
    "            of.write(' '.join(t))\n",
    "            of.write('\\n')\n",
    "        of.write('\\n')\n",
    "    of.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pred(X_test, tags_dictionary):\n",
    "    yt  = model.predict_classes(X_test[:])\n",
    "    preds = []\n",
    "    for i in np.arange(0, yt.shape[0]):\n",
    "        actual_tags = [tags_dictionary[t] for t in yt[i]]\n",
    "        ptags = actual_tags[:actual_tags.index('EOS')]\n",
    "        preds.append(ptags)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_text = ConLLReader('/data/vivek/pos_tags/train_pos.txt', True)\n",
    "tags_text = ConLLReader('/data/vivek/pos_tags/train_pos.tags')\n",
    "corpus_dictionary = gensim.corpora.Dictionary(corpus_text)\n",
    "tags_dictionary = gensim.corpora.Dictionary(tags_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_corpus_text = ConLLReader('/data/vivek/pos_tags/dev_pos.txt', True)\n",
    "dev_tags_text = ConLLReader('/data/vivek/pos_tags/dev_pos.tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_tokens = text_to_tokens(corpus_text, corpus_dictionary)\n",
    "tags_tokens = text_to_tokens(tags_text, tags_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_corpus_tokens = text_to_tokens(dev_corpus_text, corpus_dictionary)\n",
    "dev_tags_tokens = text_to_tokens(dev_tags_text, tags_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:shape (8936, 80)\n",
      "Y:shape (8936, 80, 45)\n"
     ]
    }
   ],
   "source": [
    "X,y = getXandY(corpus_tokens, tags_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:shape (2012, 80)\n",
      "Y:shape (2012, 80, 45)\n"
     ]
    }
   ],
   "source": [
    "X_test,y_test = getXandY(dev_corpus_tokens, dev_tags_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8936/8936 [==============================] - 587s - loss: 0.2525 - acc: 0.9307   \n",
      "Epoch 2/3\n",
      "8936/8936 [==============================] - 634s - loss: 0.0700 - acc: 0.9799   \n",
      "Epoch 3/3\n",
      "8936/8936 [==============================] - 632s - loss: 0.0461 - acc: 0.9867   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5157610b90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X\n",
    "Y_train = y\n",
    "nb_word = len(corpus_dictionary) + 1\n",
    "nb_tag = len(tags_dictionary) \n",
    "batch_size = 1\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_word, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(TimeDistributedDense(nb_tag))\n",
    "model.add(Activation('time_distributed_softmax'))\n",
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms,class_mode='categorical')\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=3, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012/2012 [==============================] - 4s     \n"
     ]
    }
   ],
   "source": [
    "preds = get_pred(X_test, tags_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_conll_eval('/data/vivek/pos_tags/dev_pos.txt', '/data/vivek/pos_tags/dev_pos.tags', '/data/vivek/pos_tags/test.output', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 47377 tokens with 47377 phrases; found: 47377 phrases; correct: 43804.\n",
      "accuracy:  92.46%; precision:  92.46%; recall:  92.46%; FB1:  92.46\n",
      "                #: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "                $: precision:  99.22%; recall: 100.00%; FB1:  99.61  387\n",
      "               '': precision: 100.00%; recall:  99.05%; FB1:  99.52  313\n",
      "                (: precision: 100.00%; recall: 100.00%; FB1: 100.00  77\n",
      "                ): precision: 100.00%; recall: 100.00%; FB1: 100.00  77\n",
      "                ,: precision: 100.00%; recall: 100.00%; FB1: 100.00  2390\n",
      "                .: precision: 100.00%; recall: 100.00%; FB1: 100.00  1975\n",
      "                :: precision: 100.00%; recall: 100.00%; FB1: 100.00  238\n",
      "               CC: precision: 100.00%; recall:  99.59%; FB1:  99.79  1209\n",
      "               CD: precision:  93.55%; recall:  95.99%; FB1:  94.75  1968\n",
      "               DT: precision:  99.26%; recall:  99.43%; FB1:  99.34  4027\n",
      "               EX: precision:  96.00%; recall: 100.00%; FB1:  97.96  50\n",
      "               FW: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               IN: precision:  96.37%; recall:  99.55%; FB1:  97.93  5238\n",
      "               JJ: precision:  73.95%; recall:  87.55%; FB1:  80.18  3509\n",
      "              JJR: precision:  82.43%; recall:  90.59%; FB1:  86.32  222\n",
      "              JJS: precision:  97.22%; recall:  90.91%; FB1:  93.96  72\n",
      "               MD: precision:  97.51%; recall: 100.00%; FB1:  98.74  482\n",
      "               NN: precision:  85.67%; recall:  92.08%; FB1:  88.76  7139\n",
      "              NNP: precision:  86.52%; recall:  80.15%; FB1:  83.21  4452\n",
      "             NNPS: precision:  84.44%; recall:  29.23%; FB1:  43.43  45\n",
      "              NNS: precision:  93.84%; recall:  87.80%; FB1:  90.72  2839\n",
      "              PDT: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "              POS: precision:  98.86%; recall: 100.00%; FB1:  99.43  439\n",
      "              PRP: precision:  99.88%; recall:  99.88%; FB1:  99.88  814\n",
      "             PRP$: precision: 100.00%; recall: 100.00%; FB1: 100.00  421\n",
      "               RB: precision:  96.93%; recall:  86.19%; FB1:  91.24  1204\n",
      "              RBR: precision:  81.58%; recall:  43.66%; FB1:  56.88  38\n",
      "              RBS: precision: 100.00%; recall:  97.96%; FB1:  98.97  48\n",
      "               RP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               TO: precision: 100.00%; recall: 100.00%; FB1: 100.00  1178\n",
      "               UH: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               VB: precision:  95.91%; recall:  90.46%; FB1:  93.11  1197\n",
      "              VBD: precision:  88.73%; recall:  95.65%; FB1:  92.06  1810\n",
      "              VBG: precision:  96.21%; recall:  76.65%; FB1:  85.32  580\n",
      "              VBN: precision:  90.88%; recall:  79.44%; FB1:  84.78  965\n",
      "              VBP: precision:  96.81%; recall:  90.17%; FB1:  93.37  502\n",
      "              VBZ: precision:  98.07%; recall:  89.16%; FB1:  93.40  830\n",
      "              WDT: precision:  96.52%; recall:  54.95%; FB1:  70.03  115\n",
      "               WP: precision: 100.00%; recall:  99.09%; FB1:  99.54  109\n",
      "              WP$: precision: 100.00%; recall:  75.00%; FB1:  85.71  3\n",
      "              WRB: precision: 100.00%; recall:  98.92%; FB1:  99.46  92\n",
      "               ``: precision: 100.00%; recall: 100.00%; FB1: 100.00  323\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "perl /data/vivek/pos_tags/conlleval.pl -r <  /data/vivek/pos_tags/test.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
